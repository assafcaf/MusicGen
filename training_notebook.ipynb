{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import argparse\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = datasets.load_from_disk(\"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Encoding/Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 95\n",
      "chars: ['\\n', ' ', '!', '\"', '#', '$', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "# encoding and decoding  \n",
    "chars = sorted(set(\"\\n\\n\".join(dataset[\"train\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])))\n",
    "vocab_size = len(chars) \n",
    "print(f\"vocab_size: {vocab_size}\")\n",
    "print(f\"chars: {chars}\")\n",
    "chat2index = {ch:i for i, ch in enumerate(chars)}\n",
    "index2chat = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda x: [chat2index[c] for c in x]\n",
    "decode = lambda x: \"\".join([index2chat[c] for c in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation data envoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63170498\n"
     ]
    }
   ],
   "source": [
    "# encode training data\n",
    "# dataset = dataset.map(lambda x: {\"abc notation\": encode(x[\"abc notation\"])})\n",
    "text = \"\\n\\n\".join(dataset[\"train\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])\n",
    "training_data = torch.tensor(encode(text))\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247506\n"
     ]
    }
   ],
   "source": [
    "# encode validation data\n",
    "# dataset = dataset.map(lambda x: {\"abc notation\": encode(x[\"abc notation\"])})\n",
    "text = \"\\n\\n\".join(dataset[\"validation\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])\n",
    "validation_data = torch.tensor(encode(text))\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bach generator\n",
    "def get_batch(split, block_size=8, bach_size=32):\n",
    "    if split == \"train\":\n",
    "        data = training_data\n",
    "    elif split == \"validation\":\n",
    "        data = validation_data\n",
    "    else:\n",
    "        raise ValueError(\"split must be 'train' or 'validation'\")\n",
    "    start_idx = torch.randint(0, data.size(0) - block_size, (bach_size,))\n",
    "    x = torch.stack([data[idx:idx+block_size] for idx in start_idx]).to(device)\n",
    "    y = torch.stack([data[idx+1:idx+block_size+1] for idx in start_idx]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 1, 34, 1, 34, 33, 34, 1, 92, 1, 68, 69, 70, 1, 71, 70, 71, 1, 92, 1, 69, 65, 65, 1, 65, 18, 1, 71, 1, 92, 1, 70, 68, 68, 1, 68, 18, 1, 67, 1, 92, 1, 34, 18, 1, 34, 1, 34] -> 33\n",
      "2 B BAB | def gfg | eaa a2 g | fdd d2 c | B2 B B -> A\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "bach_size = 1\n",
    "block_size = 48\n",
    "x, y = get_batch(\"train\", block_size=block_size, bach_size=bach_size)\n",
    "for b in range(bach_size):\n",
    "    for t in range(block_size):\n",
    "        context = x[b, :t+1]\n",
    "        target = y[b, t]\n",
    "    print(context.tolist(), \"->\", target.item())\n",
    "    print(decode(context.tolist()), \"->\", decode([target.item()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BigramModel, self).__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        B, T, C = logits.size()\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "        else:\n",
    "                loss = None\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, n):\n",
    "        for _ in range(n):\n",
    "            logits = self.token_embedding_table(idx)\n",
    "            next_idx = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "            idx = torch.cat([idx, next_idx], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 95])\n",
      "tensor(4.9579, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(\"train\")\n",
    "m = BigramModel(vocab_size)\n",
    "m.to(device)\n",
    "logits, loss = m(x, y)  \n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nJ2)[ *)yLorct0s$/T@\\'>3zx1G~SbJD2)[Rt)1y&cV*_1\"6&sa.x}j7SDM<\\'^E?$67R)V\\\\N/u?ruzu5|<zEWYTv>V<H#A{j[($Z5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(1, 1).long().to(device)\n",
    "g = m.generate(idx, 100)\n",
    "decode(g[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    def estimate_loss(model, eval_iters, block_size):\n",
    "        out = {}\n",
    "        model.eval()\n",
    "        for split in dataset:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for i in range(eval_iters):\n",
    "                x, y = get_batch(split, block_size)\n",
    "                _, loss = model(x, y)\n",
    "                losses[i] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "        model.train()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1000\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 4.983, validation loss: 4.966\n",
      "step: 100, train loss: 4.845, validation loss: 4.832\n",
      "step: 200, train loss: 4.715, validation loss: 4.712\n",
      "step: 300, train loss: 4.603, validation loss: 4.587\n",
      "step: 400, train loss: 4.472, validation loss: 4.473\n",
      "step: 500, train loss: 4.368, validation loss: 4.357\n",
      "step: 600, train loss: 4.252, validation loss: 4.237\n",
      "step: 700, train loss: 4.142, validation loss: 4.142\n",
      "step: 800, train loss: 4.051, validation loss: 4.046\n",
      "step: 900, train loss: 3.949, validation loss: 3.935\n"
     ]
    }
   ],
   "source": [
    "for step in range(n_iters):\n",
    "    x, y = get_batch(\"train\")\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = m(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % (n_iters//10) == 0:\n",
    "        losses = estimate_loss(m, 100, block_size)\n",
    "        print(f\"step: {step}, train loss: {losses['train']:.3f}, validation loss: {losses['validation']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iw1_b&qn,@6ilm(\"61i~IS#Tk1/2LqP{pocT#Nwry#tAG104fj[&RFa;idMVZ48^vS*I~fTQ\\'4 /A2t:NJ2ecfV]by$][BcXNJIzx[c/]i#@^]2o4!?,WY$,dK8B,D|SZ&U^m>Q+$,RS+\\'>NL2\\'Bg5f?@3_Rb\".]3fT:3+|le^+t= c}\\\\PkxW;&z94Bd\\';ikxJDh[238e?3wxh3$0x1\"A2{&eJlJWu;&YpV<$cuB,Z&8mMis0]}4?y(17k`d5$0C^X9~Z6i,W6y*ayG:1it=i.cK8BfgOU4,\\'dnY.$;iV$]L@z8TLJK8f.\\\\G3835}*r7PL@0igHG@t@B=k=B\"-2c2yD>,,\\'GEE3YQYQOr[2c>Nukx}dNVCQ3.(W7A2/TQm&uDF-[1a`Cdn7N(xdYpL(cet[Ue)^:_~1HJH$t!j_Ue5ts*2s:(c^0Fsk_xNh2:?ja!gb&eZyE2afgQy+A<ETMi(8-BGF+(GF>Ae2\\\\@#?87\"cr+teZ'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(1, 1).long().to(device)\n",
    "g = m.generate(idx, 500)\n",
    "\n",
    "decode(g[0].tolist()).replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic  transformer components\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, dropout=0.1, block_size=8):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = head_size\n",
    "        \n",
    "        self.keys = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        self.queries = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        self.value = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.keys(x) # B, block_size, head_size\n",
    "        q = self.queries(x) # B, block_size, head_size\n",
    "        v = self.value(x)\n",
    "\n",
    "        tril = torch.tril(torch.ones(T, T)).to(x.device)    \n",
    "        wei = q @ k.transpose(-2, -1) * self.head_size**-0.5  # (B, block_size, head_size) @ (B, head_size, block_size) -> (B, block_size, block_size)\n",
    "        wei = wei.masked_fill(tril == 0, float('-inf')) # B, block_size, block_size\n",
    "        wei = torch.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        out = wei @ v\n",
    "        return out\n",
    " \n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, embed_size, mlp_size, dropout=0.1):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.mlp_size = mlp_size\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, mlp_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_size, embed_size),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, n_heads, dropout=0.1, block_size=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = head_size\n",
    "        self.num_heads = n_heads\n",
    "        self.attentions = nn.ModuleList([SelfAttention(embed_size, head_size, block_size=block_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_heads * head_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([attn(x) for attn in self.attentions], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block\n",
    "class Block(nn.Module): \n",
    "    def __init__(self, embed_size, mlp_size, n_heads, dropout=0.1, block_size=8):\n",
    "        super(Block, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = embed_size // n_heads\n",
    "        self.mlp_size = mlp_size\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "        self.mha = MultiHeadAttention(embed_size, self.head_size, n_heads, dropout, block_size)\n",
    "        self.mlp = Mlp(embed_size, mlp_size, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.mha(x) + self.ln1(x)\n",
    "        out = self.mlp(self.ln2(out)) + out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_blocks=8, block_size=8, n_heads=8, dropout=0.1):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, embedding_dim)\n",
    "        self.blocks = nn.Sequential(*\n",
    "                                    [Block(embedding_dim,\n",
    "                                           embedding_dim*4,\n",
    "                                           n_heads, dropout,\n",
    "                                           block_size) for _ in range(n_blocks)],\n",
    "                                    nn.LayerNorm(embedding_dim)\n",
    "                                    )\n",
    "        self.lm_head = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        token_embeddings = self.token_embedding_table(x) # B, T, C\n",
    "        positional_embeddings = self.positional_embedding_table(torch.arange(T).to(device) )# T, C\n",
    "        x = token_embeddings + positional_embeddings # \n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        B, T, C = logits.size()\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "        else:\n",
    "                loss = None\n",
    "                \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, n):\n",
    "        for _ in range(n):\n",
    "            logits, _ = self(idx[:, -self.block_size:])\n",
    "            next_idx = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "            idx = torch.cat([idx, next_idx], dim=1)\n",
    "        return idx\n",
    "\n",
    "    def save_model(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load_model(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384 \n",
    "n_heads = 6\n",
    "head_size = 32//n_heads \n",
    "block_size = 256 # context window size\n",
    "bach_size = 64\n",
    "n_iters = 1000\n",
    "lr = 3e-4\n",
    "n_blocks = 6    \n",
    "dropout = 0.2\n",
    "m = LanguageModel(vocab_size=vocab_size,\n",
    "                  embedding_dim=embedding_dim,\n",
    "                  block_size=block_size,\n",
    "                  n_heads=n_heads,\n",
    "                  dropout=dropout,)\n",
    "m.to(device)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100, train loss: 2.088, validation loss: 2.069\n",
      "step: 200, train loss: 1.710, validation loss: 1.694\n",
      "step: 300, train loss: 1.516, validation loss: 1.521\n",
      "step: 400, train loss: 1.425, validation loss: 1.413\n",
      "step: 500, train loss: 1.343, validation loss: 1.340\n",
      "step: 600, train loss: 1.272, validation loss: 1.261\n",
      "step: 700, train loss: 1.195, validation loss: 1.196\n",
      "step: 800, train loss: 1.143, validation loss: 1.134\n",
      "step: 900, train loss: 1.103, validation loss: 1.101\n",
      "step: 1000, train loss: 1.065, validation loss: 1.077\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "with tqdm(total=len(n_iters+1), desc=f\"Iter {epoch + 1}\", unit=\"Iterations\") as p_bar:\n",
    "    for step in range(n_iters+1):\n",
    "        x, y = get_batch(\"train\", block_size, bach_size)\n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = m(x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step % (n_iters//10) == 0 and step :\n",
    "            losses = estimate_loss(m, 100, block_size=block_size)\n",
    "            print(f\"step: {step}, train loss: {losses['train']:.3f}, validation loss: {losses['validation']:.3f}\")\n",
    "        p_bar.update(1)\n",
    "m.save_model(r\"models/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prompt, n):\n",
    "    encoded_prompt = torch.tensor(encode(prompt)).unsqueeze(0).to(device)\n",
    "    print(encoded_prompt)\n",
    "    out = model.generate(encoded_prompt, n)\n",
    "    return decode(out[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0, 44, 26, 17, 15, 24,  0, 49, 26, 17, 15, 24, 29, 17, 24, 16,  0, 45,\n",
      "         26, 19, 15, 24,  0, 43, 26, 35,  0]], device='cuda:0')\n",
      "\n",
      "L:1/8\n",
      "Q:1/8=180\n",
      "M:3/8\n",
      "K:C\n",
      "jQPN3xf7ufQ1Xt`dzuC>\n",
      "<I37\";]#ap.}.x?JQCB}C'O: 1rRIZVqu$C:MTacts\"xfa4_)]\"|ke4#4f|G}O8qjU<rW7:HGG:4RC=&#yXH<:cPmy4<lL+z$9,Yyc*t\"6@\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "L:1/8\n",
    "Q:1/8=180\n",
    "M:3/8\n",
    "K:C\n",
    "\"\"\"\n",
    "m = LanguageModel(vocab_size=vocab_size,\n",
    "                  embedding_dim=embedding_dim,\n",
    "                  block_size=block_size,\n",
    "                  n_heads=n_heads,\n",
    "                  dropout=dropout)\n",
    "# m.load_model(r\"models/model.pth\")\n",
    "m.to(device)\n",
    "print(generate(m, prompt, 128))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
