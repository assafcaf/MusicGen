{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import argparse\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "block_size = 8\n",
    "bach_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = datasets.load_from_disk(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding and decoding  \n",
    "chars = sorted(set(\"\\n\\n\".join(dataset[\"train\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])))\n",
    "vocab_size = len(chars) \n",
    "chat2index = {ch:i for i, ch in enumerate(chars)}\n",
    "index2chat = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda x: [chat2index[c] for c in x]\n",
    "decode = lambda x: \"\".join([index2chat[c] for c in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode training data\n",
    "# dataset = dataset.map(lambda x: {\"abc notation\": encode(x[\"abc notation\"])})\n",
    "text = \"\\n\\n\".join(dataset[\"train\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])\n",
    "training_data = torch.tensor(encode(text))\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode validation data\n",
    "# dataset = dataset.map(lambda x: {\"abc notation\": encode(x[\"abc notation\"])})\n",
    "text = \"\\n\\n\".join(dataset[\"validation\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])\n",
    "validation_data = torch.tensor(encode(text))\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([56]) -> tensor(17)\n",
      "tensor([56, 26]) -> tensor(0)\n",
      "tensor([56, 26, 17]) -> tensor(44)\n",
      "tensor([56, 26, 17,  0]) -> tensor(26)\n",
      "tensor([56, 26, 17,  0, 44]) -> tensor(17)\n",
      "tensor([56, 26, 17,  0, 44, 26]) -> tensor(15)\n",
      "tensor([56, 26, 17,  0, 44, 26, 17]) -> tensor(24)\n"
     ]
    }
   ],
   "source": [
    "# example of training samples\n",
    "b_size = 8\n",
    "x = training_data[:b_size]\n",
    "y = training_data[1:b_size+1]\n",
    "for t in range(1, b_size):\n",
    "    context = x[:t]\n",
    "    target = y[t]\n",
    "    print(context, \"->\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bach generator\n",
    "def get_batch(split):\n",
    "    if split == \"train\":\n",
    "        data = training_data\n",
    "    elif split == \"validation\":\n",
    "        data = validation_data\n",
    "    else:\n",
    "        raise ValueError(\"split must be 'train' or 'validation'\")\n",
    "    start_idx = torch.randint(0, data.size(0) - block_size, (bach_size,))\n",
    "    x = torch.stack([data[idx:idx+block_size] for idx in start_idx]).to(device)\n",
    "    y = torch.stack([data[idx+1:idx+block_size+1] for idx in start_idx]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8]) torch.Size([32, 8])\n",
      "input\n",
      "tensor([[67,  1, 92,  1, 68, 71, 71,  1],\n",
      "        [92,  3, 36,  3,  1, 68, 18, 36],\n",
      "        [34,  1, 92,  1, 67, 68, 67,  1],\n",
      "        [61, 68,  1, 67, 69,  1, 67, 69],\n",
      "        [34, 33,  1, 39, 34, 37, 65,  1],\n",
      "        [ 1, 92,  1,  0,  1, 68, 34, 39],\n",
      "        [ 3, 39,  3,  1, 34, 69,  1, 68],\n",
      "        [67,  1, 34,  1, 33,  1, 92,  1],\n",
      "        [ 1, 14, 36, 30, 36,  1,  8, 37],\n",
      "        [37, 66,  3,  1, 37, 18,  1, 92],\n",
      "        [ 1, 65, 18,  1, 92,  1, 66, 19],\n",
      "        [39,  1, 92,  1, 34, 67, 68,  1],\n",
      "        [92,  1, 38, 33,  1, 33, 15, 34],\n",
      "        [ 1, 92,  1, 37, 33, 33,  1, 67],\n",
      "        [ 3, 33, 23,  3,  1, 65, 18, 65],\n",
      "        [68, 70, 68,  1, 92,  1,  8, 68],\n",
      "        [92,  1, 38, 39, 33, 38,  1, 36],\n",
      "        [26,  1, 33, 34,  1, 33, 18,  1],\n",
      "        [ 1,  8, 69, 65,  9,  8, 71, 66],\n",
      "        [ 1, 68, 19,  1, 92,  1, 69, 18],\n",
      "        [71, 34, 70, 34,  1, 69, 68, 34],\n",
      "        [ 1, 92,  3, 35,  3,  1, 67, 68],\n",
      "        [ 1, 37, 18,  1, 92,  1, 38, 22],\n",
      "        [69,  1, 37, 19,  1, 37, 19,  1],\n",
      "        [ 1,  8, 71, 69,  9, 14, 69,  1],\n",
      "        [ 1, 92,  1, 35, 19,  1, 34, 12],\n",
      "        [18,  1, 33, 34,  3, 36, 23,  3],\n",
      "        [ 1, 67, 33, 38, 33,  1, 92,  1],\n",
      "        [ 1,  0,  3, 37, 77,  3,  1, 71],\n",
      "        [92,  1, 71, 70, 71,  1, 34, 18],\n",
      "        [ 1, 79, 82,  1, 84, 73, 77, 69],\n",
      "        [68, 19,  1, 26, 92, 18,  3, 36]])\n",
      "target\n",
      "tensor([[ 1, 92,  1, 68, 71, 71,  1, 70],\n",
      "        [ 3, 36,  3,  1, 68, 18, 36, 18],\n",
      "        [ 1, 92,  1, 67, 68, 67,  1, 33],\n",
      "        [68,  1, 67, 69,  1, 67, 69,  1],\n",
      "        [33,  1, 39, 34, 37, 65,  1, 92],\n",
      "        [92,  1,  0,  1, 68, 34, 39, 70],\n",
      "        [39,  3,  1, 34, 69,  1, 68, 18],\n",
      "        [ 1, 34,  1, 33,  1, 92,  1, 39],\n",
      "        [14, 36, 30, 36,  1,  8, 37, 38],\n",
      "        [66,  3,  1, 37, 18,  1, 92, 61],\n",
      "        [65, 18,  1, 92,  1, 66, 19,  1],\n",
      "        [ 1, 92,  1, 34, 67, 68,  1, 68],\n",
      "        [ 1, 38, 33,  1, 33, 15, 34, 15],\n",
      "        [92,  1, 37, 33, 33,  1, 67, 34],\n",
      "        [33, 23,  3,  1, 65, 18, 65, 18],\n",
      "        [70, 68,  1, 92,  1,  8, 68, 15],\n",
      "        [ 1, 38, 39, 33, 38,  1, 36, 37],\n",
      "        [ 1, 33, 34,  1, 33, 18,  1, 65],\n",
      "        [ 8, 69, 65,  9,  8, 71, 66,  9],\n",
      "        [68, 19,  1, 92,  1, 69, 18,  1],\n",
      "        [34, 70, 34,  1, 69, 68, 34, 62],\n",
      "        [92,  3, 35,  3,  1, 67, 68, 67],\n",
      "        [37, 18,  1, 92,  1, 38, 22,  1],\n",
      "        [ 1, 37, 19,  1, 37, 19,  1, 38],\n",
      "        [ 8, 71, 69,  9, 14, 69,  1,  8],\n",
      "        [92,  1, 35, 19,  1, 34, 12,  1],\n",
      "        [ 1, 33, 34,  3, 36, 23,  3,  1],\n",
      "        [67, 33, 38, 33,  1, 92,  1, 39],\n",
      "        [ 0,  3, 37, 77,  3,  1, 71, 19],\n",
      "        [ 1, 71, 70, 71,  1, 34, 18,  1],\n",
      "        [79, 82,  1, 84, 73, 77, 69,  1],\n",
      "        [19,  1, 26, 92, 18,  3, 36,  3]])\n",
      "tensor([67]) -> tensor(1)\n",
      "tensor([67,  1]) -> tensor(92)\n",
      "tensor([67,  1, 92]) -> tensor(1)\n",
      "tensor([67,  1, 92,  1]) -> tensor(68)\n",
      "tensor([67,  1, 92,  1, 68]) -> tensor(71)\n",
      "tensor([67,  1, 92,  1, 68, 71]) -> tensor(71)\n",
      "tensor([67,  1, 92,  1, 68, 71, 71]) -> tensor(1)\n",
      "tensor([67,  1, 92,  1, 68, 71, 71,  1]) -> tensor(70)\n",
      "tensor([92]) -> tensor(3)\n",
      "tensor([92,  3]) -> tensor(36)\n",
      "tensor([92,  3, 36]) -> tensor(3)\n",
      "tensor([92,  3, 36,  3]) -> tensor(1)\n",
      "tensor([92,  3, 36,  3,  1]) -> tensor(68)\n",
      "tensor([92,  3, 36,  3,  1, 68]) -> tensor(18)\n",
      "tensor([92,  3, 36,  3,  1, 68, 18]) -> tensor(36)\n",
      "tensor([92,  3, 36,  3,  1, 68, 18, 36]) -> tensor(18)\n",
      "tensor([34]) -> tensor(1)\n",
      "tensor([34,  1]) -> tensor(92)\n",
      "tensor([34,  1, 92]) -> tensor(1)\n",
      "tensor([34,  1, 92,  1]) -> tensor(67)\n",
      "tensor([34,  1, 92,  1, 67]) -> tensor(68)\n",
      "tensor([34,  1, 92,  1, 67, 68]) -> tensor(67)\n",
      "tensor([34,  1, 92,  1, 67, 68, 67]) -> tensor(1)\n",
      "tensor([34,  1, 92,  1, 67, 68, 67,  1]) -> tensor(33)\n",
      "tensor([61]) -> tensor(68)\n",
      "tensor([61, 68]) -> tensor(1)\n",
      "tensor([61, 68,  1]) -> tensor(67)\n",
      "tensor([61, 68,  1, 67]) -> tensor(69)\n",
      "tensor([61, 68,  1, 67, 69]) -> tensor(1)\n",
      "tensor([61, 68,  1, 67, 69,  1]) -> tensor(67)\n",
      "tensor([61, 68,  1, 67, 69,  1, 67]) -> tensor(69)\n",
      "tensor([61, 68,  1, 67, 69,  1, 67, 69]) -> tensor(1)\n",
      "tensor([34]) -> tensor(33)\n",
      "tensor([34, 33]) -> tensor(1)\n",
      "tensor([34, 33,  1]) -> tensor(39)\n",
      "tensor([34, 33,  1, 39]) -> tensor(34)\n",
      "tensor([34, 33,  1, 39, 34]) -> tensor(37)\n",
      "tensor([34, 33,  1, 39, 34, 37]) -> tensor(65)\n",
      "tensor([34, 33,  1, 39, 34, 37, 65]) -> tensor(1)\n",
      "tensor([34, 33,  1, 39, 34, 37, 65,  1]) -> tensor(92)\n",
      "tensor([1]) -> tensor(92)\n",
      "tensor([ 1, 92]) -> tensor(1)\n",
      "tensor([ 1, 92,  1]) -> tensor(0)\n",
      "tensor([ 1, 92,  1,  0]) -> tensor(1)\n",
      "tensor([ 1, 92,  1,  0,  1]) -> tensor(68)\n",
      "tensor([ 1, 92,  1,  0,  1, 68]) -> tensor(34)\n",
      "tensor([ 1, 92,  1,  0,  1, 68, 34]) -> tensor(39)\n",
      "tensor([ 1, 92,  1,  0,  1, 68, 34, 39]) -> tensor(70)\n",
      "tensor([3]) -> tensor(39)\n",
      "tensor([ 3, 39]) -> tensor(3)\n",
      "tensor([ 3, 39,  3]) -> tensor(1)\n",
      "tensor([ 3, 39,  3,  1]) -> tensor(34)\n",
      "tensor([ 3, 39,  3,  1, 34]) -> tensor(69)\n",
      "tensor([ 3, 39,  3,  1, 34, 69]) -> tensor(1)\n",
      "tensor([ 3, 39,  3,  1, 34, 69,  1]) -> tensor(68)\n",
      "tensor([ 3, 39,  3,  1, 34, 69,  1, 68]) -> tensor(18)\n",
      "tensor([67]) -> tensor(1)\n",
      "tensor([67,  1]) -> tensor(34)\n",
      "tensor([67,  1, 34]) -> tensor(1)\n",
      "tensor([67,  1, 34,  1]) -> tensor(33)\n",
      "tensor([67,  1, 34,  1, 33]) -> tensor(1)\n",
      "tensor([67,  1, 34,  1, 33,  1]) -> tensor(92)\n",
      "tensor([67,  1, 34,  1, 33,  1, 92]) -> tensor(1)\n",
      "tensor([67,  1, 34,  1, 33,  1, 92,  1]) -> tensor(39)\n",
      "tensor([1]) -> tensor(14)\n",
      "tensor([ 1, 14]) -> tensor(36)\n",
      "tensor([ 1, 14, 36]) -> tensor(30)\n",
      "tensor([ 1, 14, 36, 30]) -> tensor(36)\n",
      "tensor([ 1, 14, 36, 30, 36]) -> tensor(1)\n",
      "tensor([ 1, 14, 36, 30, 36,  1]) -> tensor(8)\n",
      "tensor([ 1, 14, 36, 30, 36,  1,  8]) -> tensor(37)\n",
      "tensor([ 1, 14, 36, 30, 36,  1,  8, 37]) -> tensor(38)\n",
      "tensor([37]) -> tensor(66)\n",
      "tensor([37, 66]) -> tensor(3)\n",
      "tensor([37, 66,  3]) -> tensor(1)\n",
      "tensor([37, 66,  3,  1]) -> tensor(37)\n",
      "tensor([37, 66,  3,  1, 37]) -> tensor(18)\n",
      "tensor([37, 66,  3,  1, 37, 18]) -> tensor(1)\n",
      "tensor([37, 66,  3,  1, 37, 18,  1]) -> tensor(92)\n",
      "tensor([37, 66,  3,  1, 37, 18,  1, 92]) -> tensor(61)\n",
      "tensor([1]) -> tensor(65)\n",
      "tensor([ 1, 65]) -> tensor(18)\n",
      "tensor([ 1, 65, 18]) -> tensor(1)\n",
      "tensor([ 1, 65, 18,  1]) -> tensor(92)\n",
      "tensor([ 1, 65, 18,  1, 92]) -> tensor(1)\n",
      "tensor([ 1, 65, 18,  1, 92,  1]) -> tensor(66)\n",
      "tensor([ 1, 65, 18,  1, 92,  1, 66]) -> tensor(19)\n",
      "tensor([ 1, 65, 18,  1, 92,  1, 66, 19]) -> tensor(1)\n",
      "tensor([39]) -> tensor(1)\n",
      "tensor([39,  1]) -> tensor(92)\n",
      "tensor([39,  1, 92]) -> tensor(1)\n",
      "tensor([39,  1, 92,  1]) -> tensor(34)\n",
      "tensor([39,  1, 92,  1, 34]) -> tensor(67)\n",
      "tensor([39,  1, 92,  1, 34, 67]) -> tensor(68)\n",
      "tensor([39,  1, 92,  1, 34, 67, 68]) -> tensor(1)\n",
      "tensor([39,  1, 92,  1, 34, 67, 68,  1]) -> tensor(68)\n",
      "tensor([92]) -> tensor(1)\n",
      "tensor([92,  1]) -> tensor(38)\n",
      "tensor([92,  1, 38]) -> tensor(33)\n",
      "tensor([92,  1, 38, 33]) -> tensor(1)\n",
      "tensor([92,  1, 38, 33,  1]) -> tensor(33)\n",
      "tensor([92,  1, 38, 33,  1, 33]) -> tensor(15)\n",
      "tensor([92,  1, 38, 33,  1, 33, 15]) -> tensor(34)\n",
      "tensor([92,  1, 38, 33,  1, 33, 15, 34]) -> tensor(15)\n",
      "tensor([1]) -> tensor(92)\n",
      "tensor([ 1, 92]) -> tensor(1)\n",
      "tensor([ 1, 92,  1]) -> tensor(37)\n",
      "tensor([ 1, 92,  1, 37]) -> tensor(33)\n",
      "tensor([ 1, 92,  1, 37, 33]) -> tensor(33)\n",
      "tensor([ 1, 92,  1, 37, 33, 33]) -> tensor(1)\n",
      "tensor([ 1, 92,  1, 37, 33, 33,  1]) -> tensor(67)\n",
      "tensor([ 1, 92,  1, 37, 33, 33,  1, 67]) -> tensor(34)\n",
      "tensor([3]) -> tensor(33)\n",
      "tensor([ 3, 33]) -> tensor(23)\n",
      "tensor([ 3, 33, 23]) -> tensor(3)\n",
      "tensor([ 3, 33, 23,  3]) -> tensor(1)\n",
      "tensor([ 3, 33, 23,  3,  1]) -> tensor(65)\n",
      "tensor([ 3, 33, 23,  3,  1, 65]) -> tensor(18)\n",
      "tensor([ 3, 33, 23,  3,  1, 65, 18]) -> tensor(65)\n",
      "tensor([ 3, 33, 23,  3,  1, 65, 18, 65]) -> tensor(18)\n",
      "tensor([68]) -> tensor(70)\n",
      "tensor([68, 70]) -> tensor(68)\n",
      "tensor([68, 70, 68]) -> tensor(1)\n",
      "tensor([68, 70, 68,  1]) -> tensor(92)\n",
      "tensor([68, 70, 68,  1, 92]) -> tensor(1)\n",
      "tensor([68, 70, 68,  1, 92,  1]) -> tensor(8)\n",
      "tensor([68, 70, 68,  1, 92,  1,  8]) -> tensor(68)\n",
      "tensor([68, 70, 68,  1, 92,  1,  8, 68]) -> tensor(15)\n",
      "tensor([92]) -> tensor(1)\n",
      "tensor([92,  1]) -> tensor(38)\n",
      "tensor([92,  1, 38]) -> tensor(39)\n",
      "tensor([92,  1, 38, 39]) -> tensor(33)\n",
      "tensor([92,  1, 38, 39, 33]) -> tensor(38)\n",
      "tensor([92,  1, 38, 39, 33, 38]) -> tensor(1)\n",
      "tensor([92,  1, 38, 39, 33, 38,  1]) -> tensor(36)\n",
      "tensor([92,  1, 38, 39, 33, 38,  1, 36]) -> tensor(37)\n",
      "tensor([26]) -> tensor(1)\n",
      "tensor([26,  1]) -> tensor(33)\n",
      "tensor([26,  1, 33]) -> tensor(34)\n",
      "tensor([26,  1, 33, 34]) -> tensor(1)\n",
      "tensor([26,  1, 33, 34,  1]) -> tensor(33)\n",
      "tensor([26,  1, 33, 34,  1, 33]) -> tensor(18)\n",
      "tensor([26,  1, 33, 34,  1, 33, 18]) -> tensor(1)\n",
      "tensor([26,  1, 33, 34,  1, 33, 18,  1]) -> tensor(65)\n",
      "tensor([1]) -> tensor(8)\n",
      "tensor([1, 8]) -> tensor(69)\n",
      "tensor([ 1,  8, 69]) -> tensor(65)\n",
      "tensor([ 1,  8, 69, 65]) -> tensor(9)\n",
      "tensor([ 1,  8, 69, 65,  9]) -> tensor(8)\n",
      "tensor([ 1,  8, 69, 65,  9,  8]) -> tensor(71)\n",
      "tensor([ 1,  8, 69, 65,  9,  8, 71]) -> tensor(66)\n",
      "tensor([ 1,  8, 69, 65,  9,  8, 71, 66]) -> tensor(9)\n",
      "tensor([1]) -> tensor(68)\n",
      "tensor([ 1, 68]) -> tensor(19)\n",
      "tensor([ 1, 68, 19]) -> tensor(1)\n",
      "tensor([ 1, 68, 19,  1]) -> tensor(92)\n",
      "tensor([ 1, 68, 19,  1, 92]) -> tensor(1)\n",
      "tensor([ 1, 68, 19,  1, 92,  1]) -> tensor(69)\n",
      "tensor([ 1, 68, 19,  1, 92,  1, 69]) -> tensor(18)\n",
      "tensor([ 1, 68, 19,  1, 92,  1, 69, 18]) -> tensor(1)\n",
      "tensor([71]) -> tensor(34)\n",
      "tensor([71, 34]) -> tensor(70)\n",
      "tensor([71, 34, 70]) -> tensor(34)\n",
      "tensor([71, 34, 70, 34]) -> tensor(1)\n",
      "tensor([71, 34, 70, 34,  1]) -> tensor(69)\n",
      "tensor([71, 34, 70, 34,  1, 69]) -> tensor(68)\n",
      "tensor([71, 34, 70, 34,  1, 69, 68]) -> tensor(34)\n",
      "tensor([71, 34, 70, 34,  1, 69, 68, 34]) -> tensor(62)\n",
      "tensor([1]) -> tensor(92)\n",
      "tensor([ 1, 92]) -> tensor(3)\n",
      "tensor([ 1, 92,  3]) -> tensor(35)\n",
      "tensor([ 1, 92,  3, 35]) -> tensor(3)\n",
      "tensor([ 1, 92,  3, 35,  3]) -> tensor(1)\n",
      "tensor([ 1, 92,  3, 35,  3,  1]) -> tensor(67)\n",
      "tensor([ 1, 92,  3, 35,  3,  1, 67]) -> tensor(68)\n",
      "tensor([ 1, 92,  3, 35,  3,  1, 67, 68]) -> tensor(67)\n",
      "tensor([1]) -> tensor(37)\n",
      "tensor([ 1, 37]) -> tensor(18)\n",
      "tensor([ 1, 37, 18]) -> tensor(1)\n",
      "tensor([ 1, 37, 18,  1]) -> tensor(92)\n",
      "tensor([ 1, 37, 18,  1, 92]) -> tensor(1)\n",
      "tensor([ 1, 37, 18,  1, 92,  1]) -> tensor(38)\n",
      "tensor([ 1, 37, 18,  1, 92,  1, 38]) -> tensor(22)\n",
      "tensor([ 1, 37, 18,  1, 92,  1, 38, 22]) -> tensor(1)\n",
      "tensor([69]) -> tensor(1)\n",
      "tensor([69,  1]) -> tensor(37)\n",
      "tensor([69,  1, 37]) -> tensor(19)\n",
      "tensor([69,  1, 37, 19]) -> tensor(1)\n",
      "tensor([69,  1, 37, 19,  1]) -> tensor(37)\n",
      "tensor([69,  1, 37, 19,  1, 37]) -> tensor(19)\n",
      "tensor([69,  1, 37, 19,  1, 37, 19]) -> tensor(1)\n",
      "tensor([69,  1, 37, 19,  1, 37, 19,  1]) -> tensor(38)\n",
      "tensor([1]) -> tensor(8)\n",
      "tensor([1, 8]) -> tensor(71)\n",
      "tensor([ 1,  8, 71]) -> tensor(69)\n",
      "tensor([ 1,  8, 71, 69]) -> tensor(9)\n",
      "tensor([ 1,  8, 71, 69,  9]) -> tensor(14)\n",
      "tensor([ 1,  8, 71, 69,  9, 14]) -> tensor(69)\n",
      "tensor([ 1,  8, 71, 69,  9, 14, 69]) -> tensor(1)\n",
      "tensor([ 1,  8, 71, 69,  9, 14, 69,  1]) -> tensor(8)\n",
      "tensor([1]) -> tensor(92)\n",
      "tensor([ 1, 92]) -> tensor(1)\n",
      "tensor([ 1, 92,  1]) -> tensor(35)\n",
      "tensor([ 1, 92,  1, 35]) -> tensor(19)\n",
      "tensor([ 1, 92,  1, 35, 19]) -> tensor(1)\n",
      "tensor([ 1, 92,  1, 35, 19,  1]) -> tensor(34)\n",
      "tensor([ 1, 92,  1, 35, 19,  1, 34]) -> tensor(12)\n",
      "tensor([ 1, 92,  1, 35, 19,  1, 34, 12]) -> tensor(1)\n",
      "tensor([18]) -> tensor(1)\n",
      "tensor([18,  1]) -> tensor(33)\n",
      "tensor([18,  1, 33]) -> tensor(34)\n",
      "tensor([18,  1, 33, 34]) -> tensor(3)\n",
      "tensor([18,  1, 33, 34,  3]) -> tensor(36)\n",
      "tensor([18,  1, 33, 34,  3, 36]) -> tensor(23)\n",
      "tensor([18,  1, 33, 34,  3, 36, 23]) -> tensor(3)\n",
      "tensor([18,  1, 33, 34,  3, 36, 23,  3]) -> tensor(1)\n",
      "tensor([1]) -> tensor(67)\n",
      "tensor([ 1, 67]) -> tensor(33)\n",
      "tensor([ 1, 67, 33]) -> tensor(38)\n",
      "tensor([ 1, 67, 33, 38]) -> tensor(33)\n",
      "tensor([ 1, 67, 33, 38, 33]) -> tensor(1)\n",
      "tensor([ 1, 67, 33, 38, 33,  1]) -> tensor(92)\n",
      "tensor([ 1, 67, 33, 38, 33,  1, 92]) -> tensor(1)\n",
      "tensor([ 1, 67, 33, 38, 33,  1, 92,  1]) -> tensor(39)\n",
      "tensor([1]) -> tensor(0)\n",
      "tensor([1, 0]) -> tensor(3)\n",
      "tensor([1, 0, 3]) -> tensor(37)\n",
      "tensor([ 1,  0,  3, 37]) -> tensor(77)\n",
      "tensor([ 1,  0,  3, 37, 77]) -> tensor(3)\n",
      "tensor([ 1,  0,  3, 37, 77,  3]) -> tensor(1)\n",
      "tensor([ 1,  0,  3, 37, 77,  3,  1]) -> tensor(71)\n",
      "tensor([ 1,  0,  3, 37, 77,  3,  1, 71]) -> tensor(19)\n",
      "tensor([92]) -> tensor(1)\n",
      "tensor([92,  1]) -> tensor(71)\n",
      "tensor([92,  1, 71]) -> tensor(70)\n",
      "tensor([92,  1, 71, 70]) -> tensor(71)\n",
      "tensor([92,  1, 71, 70, 71]) -> tensor(1)\n",
      "tensor([92,  1, 71, 70, 71,  1]) -> tensor(34)\n",
      "tensor([92,  1, 71, 70, 71,  1, 34]) -> tensor(18)\n",
      "tensor([92,  1, 71, 70, 71,  1, 34, 18]) -> tensor(1)\n",
      "tensor([1]) -> tensor(79)\n",
      "tensor([ 1, 79]) -> tensor(82)\n",
      "tensor([ 1, 79, 82]) -> tensor(1)\n",
      "tensor([ 1, 79, 82,  1]) -> tensor(84)\n",
      "tensor([ 1, 79, 82,  1, 84]) -> tensor(73)\n",
      "tensor([ 1, 79, 82,  1, 84, 73]) -> tensor(77)\n",
      "tensor([ 1, 79, 82,  1, 84, 73, 77]) -> tensor(69)\n",
      "tensor([ 1, 79, 82,  1, 84, 73, 77, 69]) -> tensor(1)\n",
      "tensor([68]) -> tensor(19)\n",
      "tensor([68, 19]) -> tensor(1)\n",
      "tensor([68, 19,  1]) -> tensor(26)\n",
      "tensor([68, 19,  1, 26]) -> tensor(92)\n",
      "tensor([68, 19,  1, 26, 92]) -> tensor(18)\n",
      "tensor([68, 19,  1, 26, 92, 18]) -> tensor(3)\n",
      "tensor([68, 19,  1, 26, 92, 18,  3]) -> tensor(36)\n",
      "tensor([68, 19,  1, 26, 92, 18,  3, 36]) -> tensor(3)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x, y = get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "print('input')\n",
    "print(x)\n",
    "print('target')\n",
    "print(y)\n",
    "\n",
    "for b in range(bach_size):\n",
    "    for t in range(block_size):\n",
    "        context = x[b, :t+1]\n",
    "        target = y[b, t]\n",
    "        print(context, \"->\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BigramModel, self).__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        B, T, C = logits.size()\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "        else:\n",
    "                loss = None\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, n):\n",
    "        for _ in range(n):\n",
    "            logits = self.token_embedding_table(idx)\n",
    "            next_idx = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "            idx = torch.cat([idx, next_idx], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 95])\n",
      "tensor(5.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(\"train\")\n",
    "m = BigramModel(vocab_size)\n",
    "m.to(device)\n",
    "logits, loss = m(x, y)  \n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n d/c2 FDEE2 | :F2 f\\'df/D AG D | :12 A/G/) | |\"!e/aed A D | dor\" dce Bc D7374\\nQ:| AG,] fedb2 g A d/ B'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(1, 1).long().to(device)\n",
    "g = m.generate(idx, 100)\n",
    "decode(g[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model, eval_iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in dataset:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i in range(eval_iters):\n",
    "            x, y = get_batch(split)\n",
    "            _, loss = model(x, y)\n",
    "            losses[i] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 10000\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 5.090, validation loss: 5.091\n",
      "step: 1000, train loss: 3.952, validation loss: 3.940\n",
      "step: 2000, train loss: 3.199, validation loss: 3.190\n",
      "step: 3000, train loss: 2.770, validation loss: 2.743\n",
      "step: 4000, train loss: 2.516, validation loss: 2.522\n",
      "step: 5000, train loss: 2.419, validation loss: 2.411\n",
      "step: 6000, train loss: 2.379, validation loss: 2.359\n",
      "step: 7000, train loss: 2.351, validation loss: 2.324\n",
      "step: 8000, train loss: 2.342, validation loss: 2.301\n",
      "step: 9000, train loss: 2.306, validation loss: 2.290\n"
     ]
    }
   ],
   "source": [
    "for step in range(n_iters):\n",
    "    x, y = get_batch(\"train\")\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = m(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % (n_iters//10) == 0:\n",
    "        losses = estimate_loss(m, 100)\n",
    "        print(f\"step: {step}, train loss: {losses['train']:.3f}, validation loss: {losses['validation']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' f G) B, |\" | d\"DFGB c2 :1/2 | :52cB E |:GAAG | f [G F G2 cB2 :4 E cAG2 | | ABAG2 F2 fd\\'bag>[Bc2 | G | f e cB :A G2 GF Fd a2 dc2 E2d fg | d A g d2 B c ga2 gef.F fee\\'bd ec d :4/F2 efa\" c4 d |\" A |][E\"G | d c3 cA/dA FE efgf AEA2>VK:7\"B ed3 ef d>Bc |{G [E45L: e2 A | |\"Da G2 c2 d c  fgf :12dcd e (3F4]L:C2/) | d2 G/83 aar\"Em\" | |]49@BA cB e2 c2 |\" ceGE3 c cGB,2 Bc/A3 ef2Q:11/)A2/A ed>EF GA FCd/dB2 d2 A cA7\"G D>^_A[HJ~$ || | [e/g207\"G GF d2 dG2 ata!gb2X:1/2 |18\"A<E4 | f BGFE(G2 Ae2 | e fgc G/d2'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(1, 1).long().to(device)\n",
    "g = m.generate(idx, 500)\n",
    "\n",
    "decode(g[0].tolist()).replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
