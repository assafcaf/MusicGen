{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import argparse\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "block_size = 8\n",
    "bach_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataset = datasets.load_from_disk(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding and decoding  \n",
    "chars = sorted(set(\"\\n\\n\".join(dataset[\"train\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])))\n",
    "vocab_size = len(chars) \n",
    "chat2index = {ch:i for i, ch in enumerate(chars)}\n",
    "index2chat = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda x: [chat2index[c] for c in x]\n",
    "decode = lambda x: \"\".join([index2chat[c] for c in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63170498\n"
     ]
    }
   ],
   "source": [
    "# encode training data\n",
    "# dataset = dataset.map(lambda x: {\"abc notation\": encode(x[\"abc notation\"])})\n",
    "text = \"\\n\\n\".join(dataset[\"train\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])\n",
    "training_data = torch.tensor(encode(text))\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247506\n"
     ]
    }
   ],
   "source": [
    "# encode validation data\n",
    "# dataset = dataset.map(lambda x: {\"abc notation\": encode(x[\"abc notation\"])})\n",
    "text = \"\\n\\n\".join(dataset[\"validation\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])\n",
    "validation_data = torch.tensor(encode(text))\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([56]) -> tensor(17)\n",
      "tensor([56, 26]) -> tensor(0)\n",
      "tensor([56, 26, 17]) -> tensor(44)\n",
      "tensor([56, 26, 17,  0]) -> tensor(26)\n",
      "tensor([56, 26, 17,  0, 44]) -> tensor(17)\n",
      "tensor([56, 26, 17,  0, 44, 26]) -> tensor(15)\n",
      "tensor([56, 26, 17,  0, 44, 26, 17]) -> tensor(24)\n"
     ]
    }
   ],
   "source": [
    "# example of training samples\n",
    "b_size = 8\n",
    "x = training_data[:b_size]\n",
    "y = training_data[1:b_size+1]\n",
    "for t in range(1, b_size):\n",
    "    context = x[:t]\n",
    "    target = y[t]\n",
    "    print(context, \"->\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bach generator\n",
    "def get_batch(split, block_size=8, bach_size=32):\n",
    "    if split == \"train\":\n",
    "        data = training_data\n",
    "    elif split == \"validation\":\n",
    "        data = validation_data\n",
    "    else:\n",
    "        raise ValueError(\"split must be 'train' or 'validation'\")\n",
    "    start_idx = torch.randint(0, data.size(0) - block_size, (bach_size,))\n",
    "    x = torch.stack([data[idx:idx+block_size] for idx in start_idx]).to(device)\n",
    "    y = torch.stack([data[idx+1:idx+block_size+1] for idx in start_idx]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8]) torch.Size([32, 8])\n",
      "input\n",
      "tensor([[67,  1, 92,  1, 68, 71, 71,  1],\n",
      "        [92,  3, 36,  3,  1, 68, 18, 36],\n",
      "        [34,  1, 92,  1, 67, 68, 67,  1],\n",
      "        [61, 68,  1, 67, 69,  1, 67, 69],\n",
      "        [34, 33,  1, 39, 34, 37, 65,  1],\n",
      "        [ 1, 92,  1,  0,  1, 68, 34, 39],\n",
      "        [ 3, 39,  3,  1, 34, 69,  1, 68],\n",
      "        [67,  1, 34,  1, 33,  1, 92,  1],\n",
      "        [ 1, 14, 36, 30, 36,  1,  8, 37],\n",
      "        [37, 66,  3,  1, 37, 18,  1, 92],\n",
      "        [ 1, 65, 18,  1, 92,  1, 66, 19],\n",
      "        [39,  1, 92,  1, 34, 67, 68,  1],\n",
      "        [92,  1, 38, 33,  1, 33, 15, 34],\n",
      "        [ 1, 92,  1, 37, 33, 33,  1, 67],\n",
      "        [ 3, 33, 23,  3,  1, 65, 18, 65],\n",
      "        [68, 70, 68,  1, 92,  1,  8, 68],\n",
      "        [92,  1, 38, 39, 33, 38,  1, 36],\n",
      "        [26,  1, 33, 34,  1, 33, 18,  1],\n",
      "        [ 1,  8, 69, 65,  9,  8, 71, 66],\n",
      "        [ 1, 68, 19,  1, 92,  1, 69, 18],\n",
      "        [71, 34, 70, 34,  1, 69, 68, 34],\n",
      "        [ 1, 92,  3, 35,  3,  1, 67, 68],\n",
      "        [ 1, 37, 18,  1, 92,  1, 38, 22],\n",
      "        [69,  1, 37, 19,  1, 37, 19,  1],\n",
      "        [ 1,  8, 71, 69,  9, 14, 69,  1],\n",
      "        [ 1, 92,  1, 35, 19,  1, 34, 12],\n",
      "        [18,  1, 33, 34,  3, 36, 23,  3],\n",
      "        [ 1, 67, 33, 38, 33,  1, 92,  1],\n",
      "        [ 1,  0,  3, 37, 77,  3,  1, 71],\n",
      "        [92,  1, 71, 70, 71,  1, 34, 18],\n",
      "        [ 1, 79, 82,  1, 84, 73, 77, 69],\n",
      "        [68, 19,  1, 26, 92, 18,  3, 36]], device='cuda:0')\n",
      "target\n",
      "tensor([[ 1, 92,  1, 68, 71, 71,  1, 70],\n",
      "        [ 3, 36,  3,  1, 68, 18, 36, 18],\n",
      "        [ 1, 92,  1, 67, 68, 67,  1, 33],\n",
      "        [68,  1, 67, 69,  1, 67, 69,  1],\n",
      "        [33,  1, 39, 34, 37, 65,  1, 92],\n",
      "        [92,  1,  0,  1, 68, 34, 39, 70],\n",
      "        [39,  3,  1, 34, 69,  1, 68, 18],\n",
      "        [ 1, 34,  1, 33,  1, 92,  1, 39],\n",
      "        [14, 36, 30, 36,  1,  8, 37, 38],\n",
      "        [66,  3,  1, 37, 18,  1, 92, 61],\n",
      "        [65, 18,  1, 92,  1, 66, 19,  1],\n",
      "        [ 1, 92,  1, 34, 67, 68,  1, 68],\n",
      "        [ 1, 38, 33,  1, 33, 15, 34, 15],\n",
      "        [92,  1, 37, 33, 33,  1, 67, 34],\n",
      "        [33, 23,  3,  1, 65, 18, 65, 18],\n",
      "        [70, 68,  1, 92,  1,  8, 68, 15],\n",
      "        [ 1, 38, 39, 33, 38,  1, 36, 37],\n",
      "        [ 1, 33, 34,  1, 33, 18,  1, 65],\n",
      "        [ 8, 69, 65,  9,  8, 71, 66,  9],\n",
      "        [68, 19,  1, 92,  1, 69, 18,  1],\n",
      "        [34, 70, 34,  1, 69, 68, 34, 62],\n",
      "        [92,  3, 35,  3,  1, 67, 68, 67],\n",
      "        [37, 18,  1, 92,  1, 38, 22,  1],\n",
      "        [ 1, 37, 19,  1, 37, 19,  1, 38],\n",
      "        [ 8, 71, 69,  9, 14, 69,  1,  8],\n",
      "        [92,  1, 35, 19,  1, 34, 12,  1],\n",
      "        [ 1, 33, 34,  3, 36, 23,  3,  1],\n",
      "        [67, 33, 38, 33,  1, 92,  1, 39],\n",
      "        [ 0,  3, 37, 77,  3,  1, 71, 19],\n",
      "        [ 1, 71, 70, 71,  1, 34, 18,  1],\n",
      "        [79, 82,  1, 84, 73, 77, 69,  1],\n",
      "        [19,  1, 26, 92, 18,  3, 36,  3]], device='cuda:0')\n",
      "tensor([67], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([67,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([67,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([67,  1, 92,  1], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([67,  1, 92,  1, 68], device='cuda:0') -> tensor(71, device='cuda:0')\n",
      "tensor([67,  1, 92,  1, 68, 71], device='cuda:0') -> tensor(71, device='cuda:0')\n",
      "tensor([67,  1, 92,  1, 68, 71, 71], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([67,  1, 92,  1, 68, 71, 71,  1], device='cuda:0') -> tensor(70, device='cuda:0')\n",
      "tensor([92], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([92,  3], device='cuda:0') -> tensor(36, device='cuda:0')\n",
      "tensor([92,  3, 36], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([92,  3, 36,  3], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([92,  3, 36,  3,  1], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([92,  3, 36,  3,  1, 68], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([92,  3, 36,  3,  1, 68, 18], device='cuda:0') -> tensor(36, device='cuda:0')\n",
      "tensor([92,  3, 36,  3,  1, 68, 18, 36], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([34], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([34,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([34,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([34,  1, 92,  1], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([34,  1, 92,  1, 67], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([34,  1, 92,  1, 67, 68], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([34,  1, 92,  1, 67, 68, 67], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([34,  1, 92,  1, 67, 68, 67,  1], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([61], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([61, 68], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([61, 68,  1], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([61, 68,  1, 67], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([61, 68,  1, 67, 69], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([61, 68,  1, 67, 69,  1], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([61, 68,  1, 67, 69,  1, 67], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([61, 68,  1, 67, 69,  1, 67, 69], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([34], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([34, 33], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([34, 33,  1], device='cuda:0') -> tensor(39, device='cuda:0')\n",
      "tensor([34, 33,  1, 39], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([34, 33,  1, 39, 34], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([34, 33,  1, 39, 34, 37], device='cuda:0') -> tensor(65, device='cuda:0')\n",
      "tensor([34, 33,  1, 39, 34, 37, 65], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([34, 33,  1, 39, 34, 37, 65,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([ 1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 92,  1], device='cuda:0') -> tensor(0, device='cuda:0')\n",
      "tensor([ 1, 92,  1,  0], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 92,  1,  0,  1], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([ 1, 92,  1,  0,  1, 68], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([ 1, 92,  1,  0,  1, 68, 34], device='cuda:0') -> tensor(39, device='cuda:0')\n",
      "tensor([ 1, 92,  1,  0,  1, 68, 34, 39], device='cuda:0') -> tensor(70, device='cuda:0')\n",
      "tensor([3], device='cuda:0') -> tensor(39, device='cuda:0')\n",
      "tensor([ 3, 39], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([ 3, 39,  3], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 3, 39,  3,  1], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([ 3, 39,  3,  1, 34], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([ 3, 39,  3,  1, 34, 69], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 3, 39,  3,  1, 34, 69,  1], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([ 3, 39,  3,  1, 34, 69,  1, 68], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([67], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([67,  1], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([67,  1, 34], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([67,  1, 34,  1], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([67,  1, 34,  1, 33], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([67,  1, 34,  1, 33,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([67,  1, 34,  1, 33,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([67,  1, 34,  1, 33,  1, 92,  1], device='cuda:0') -> tensor(39, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(14, device='cuda:0')\n",
      "tensor([ 1, 14], device='cuda:0') -> tensor(36, device='cuda:0')\n",
      "tensor([ 1, 14, 36], device='cuda:0') -> tensor(30, device='cuda:0')\n",
      "tensor([ 1, 14, 36, 30], device='cuda:0') -> tensor(36, device='cuda:0')\n",
      "tensor([ 1, 14, 36, 30, 36], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 14, 36, 30, 36,  1], device='cuda:0') -> tensor(8, device='cuda:0')\n",
      "tensor([ 1, 14, 36, 30, 36,  1,  8], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([ 1, 14, 36, 30, 36,  1,  8, 37], device='cuda:0') -> tensor(38, device='cuda:0')\n",
      "tensor([37], device='cuda:0') -> tensor(66, device='cuda:0')\n",
      "tensor([37, 66], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([37, 66,  3], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([37, 66,  3,  1], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([37, 66,  3,  1, 37], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([37, 66,  3,  1, 37, 18], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([37, 66,  3,  1, 37, 18,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([37, 66,  3,  1, 37, 18,  1, 92], device='cuda:0') -> tensor(61, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(65, device='cuda:0')\n",
      "tensor([ 1, 65], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([ 1, 65, 18], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 65, 18,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([ 1, 65, 18,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 65, 18,  1, 92,  1], device='cuda:0') -> tensor(66, device='cuda:0')\n",
      "tensor([ 1, 65, 18,  1, 92,  1, 66], device='cuda:0') -> tensor(19, device='cuda:0')\n",
      "tensor([ 1, 65, 18,  1, 92,  1, 66, 19], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([39], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([39,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([39,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([39,  1, 92,  1], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([39,  1, 92,  1, 34], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([39,  1, 92,  1, 34, 67], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([39,  1, 92,  1, 34, 67, 68], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([39,  1, 92,  1, 34, 67, 68,  1], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([92,  1], device='cuda:0') -> tensor(38, device='cuda:0')\n",
      "tensor([92,  1, 38], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([92,  1, 38, 33], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([92,  1, 38, 33,  1], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([92,  1, 38, 33,  1, 33], device='cuda:0') -> tensor(15, device='cuda:0')\n",
      "tensor([92,  1, 38, 33,  1, 33, 15], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([92,  1, 38, 33,  1, 33, 15, 34], device='cuda:0') -> tensor(15, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([ 1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 92,  1], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 37], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 37, 33], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 37, 33, 33], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 37, 33, 33,  1], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 37, 33, 33,  1, 67], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([3], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([ 3, 33], device='cuda:0') -> tensor(23, device='cuda:0')\n",
      "tensor([ 3, 33, 23], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([ 3, 33, 23,  3], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 3, 33, 23,  3,  1], device='cuda:0') -> tensor(65, device='cuda:0')\n",
      "tensor([ 3, 33, 23,  3,  1, 65], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([ 3, 33, 23,  3,  1, 65, 18], device='cuda:0') -> tensor(65, device='cuda:0')\n",
      "tensor([ 3, 33, 23,  3,  1, 65, 18, 65], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([68], device='cuda:0') -> tensor(70, device='cuda:0')\n",
      "tensor([68, 70], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([68, 70, 68], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([68, 70, 68,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([68, 70, 68,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([68, 70, 68,  1, 92,  1], device='cuda:0') -> tensor(8, device='cuda:0')\n",
      "tensor([68, 70, 68,  1, 92,  1,  8], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([68, 70, 68,  1, 92,  1,  8, 68], device='cuda:0') -> tensor(15, device='cuda:0')\n",
      "tensor([92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([92,  1], device='cuda:0') -> tensor(38, device='cuda:0')\n",
      "tensor([92,  1, 38], device='cuda:0') -> tensor(39, device='cuda:0')\n",
      "tensor([92,  1, 38, 39], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([92,  1, 38, 39, 33], device='cuda:0') -> tensor(38, device='cuda:0')\n",
      "tensor([92,  1, 38, 39, 33, 38], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([92,  1, 38, 39, 33, 38,  1], device='cuda:0') -> tensor(36, device='cuda:0')\n",
      "tensor([92,  1, 38, 39, 33, 38,  1, 36], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([26], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([26,  1], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([26,  1, 33], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([26,  1, 33, 34], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([26,  1, 33, 34,  1], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([26,  1, 33, 34,  1, 33], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([26,  1, 33, 34,  1, 33, 18], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([26,  1, 33, 34,  1, 33, 18,  1], device='cuda:0') -> tensor(65, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(8, device='cuda:0')\n",
      "tensor([1, 8], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([ 1,  8, 69], device='cuda:0') -> tensor(65, device='cuda:0')\n",
      "tensor([ 1,  8, 69, 65], device='cuda:0') -> tensor(9, device='cuda:0')\n",
      "tensor([ 1,  8, 69, 65,  9], device='cuda:0') -> tensor(8, device='cuda:0')\n",
      "tensor([ 1,  8, 69, 65,  9,  8], device='cuda:0') -> tensor(71, device='cuda:0')\n",
      "tensor([ 1,  8, 69, 65,  9,  8, 71], device='cuda:0') -> tensor(66, device='cuda:0')\n",
      "tensor([ 1,  8, 69, 65,  9,  8, 71, 66], device='cuda:0') -> tensor(9, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([ 1, 68], device='cuda:0') -> tensor(19, device='cuda:0')\n",
      "tensor([ 1, 68, 19], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 68, 19,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([ 1, 68, 19,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 68, 19,  1, 92,  1], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([ 1, 68, 19,  1, 92,  1, 69], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([ 1, 68, 19,  1, 92,  1, 69, 18], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([71], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([71, 34], device='cuda:0') -> tensor(70, device='cuda:0')\n",
      "tensor([71, 34, 70], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([71, 34, 70, 34], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([71, 34, 70, 34,  1], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([71, 34, 70, 34,  1, 69], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([71, 34, 70, 34,  1, 69, 68], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([71, 34, 70, 34,  1, 69, 68, 34], device='cuda:0') -> tensor(62, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([ 1, 92], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([ 1, 92,  3], device='cuda:0') -> tensor(35, device='cuda:0')\n",
      "tensor([ 1, 92,  3, 35], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([ 1, 92,  3, 35,  3], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 92,  3, 35,  3,  1], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([ 1, 92,  3, 35,  3,  1, 67], device='cuda:0') -> tensor(68, device='cuda:0')\n",
      "tensor([ 1, 92,  3, 35,  3,  1, 67, 68], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([ 1, 37], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([ 1, 37, 18], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 37, 18,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([ 1, 37, 18,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 37, 18,  1, 92,  1], device='cuda:0') -> tensor(38, device='cuda:0')\n",
      "tensor([ 1, 37, 18,  1, 92,  1, 38], device='cuda:0') -> tensor(22, device='cuda:0')\n",
      "tensor([ 1, 37, 18,  1, 92,  1, 38, 22], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([69], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([69,  1], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([69,  1, 37], device='cuda:0') -> tensor(19, device='cuda:0')\n",
      "tensor([69,  1, 37, 19], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([69,  1, 37, 19,  1], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([69,  1, 37, 19,  1, 37], device='cuda:0') -> tensor(19, device='cuda:0')\n",
      "tensor([69,  1, 37, 19,  1, 37, 19], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([69,  1, 37, 19,  1, 37, 19,  1], device='cuda:0') -> tensor(38, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(8, device='cuda:0')\n",
      "tensor([1, 8], device='cuda:0') -> tensor(71, device='cuda:0')\n",
      "tensor([ 1,  8, 71], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([ 1,  8, 71, 69], device='cuda:0') -> tensor(9, device='cuda:0')\n",
      "tensor([ 1,  8, 71, 69,  9], device='cuda:0') -> tensor(14, device='cuda:0')\n",
      "tensor([ 1,  8, 71, 69,  9, 14], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([ 1,  8, 71, 69,  9, 14, 69], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1,  8, 71, 69,  9, 14, 69,  1], device='cuda:0') -> tensor(8, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([ 1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 92,  1], device='cuda:0') -> tensor(35, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 35], device='cuda:0') -> tensor(19, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 35, 19], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 35, 19,  1], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 35, 19,  1, 34], device='cuda:0') -> tensor(12, device='cuda:0')\n",
      "tensor([ 1, 92,  1, 35, 19,  1, 34, 12], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([18], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([18,  1], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([18,  1, 33], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([18,  1, 33, 34], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([18,  1, 33, 34,  3], device='cuda:0') -> tensor(36, device='cuda:0')\n",
      "tensor([18,  1, 33, 34,  3, 36], device='cuda:0') -> tensor(23, device='cuda:0')\n",
      "tensor([18,  1, 33, 34,  3, 36, 23], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([18,  1, 33, 34,  3, 36, 23,  3], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(67, device='cuda:0')\n",
      "tensor([ 1, 67], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([ 1, 67, 33], device='cuda:0') -> tensor(38, device='cuda:0')\n",
      "tensor([ 1, 67, 33, 38], device='cuda:0') -> tensor(33, device='cuda:0')\n",
      "tensor([ 1, 67, 33, 38, 33], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 67, 33, 38, 33,  1], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([ 1, 67, 33, 38, 33,  1, 92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 67, 33, 38, 33,  1, 92,  1], device='cuda:0') -> tensor(39, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(0, device='cuda:0')\n",
      "tensor([1, 0], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([1, 0, 3], device='cuda:0') -> tensor(37, device='cuda:0')\n",
      "tensor([ 1,  0,  3, 37], device='cuda:0') -> tensor(77, device='cuda:0')\n",
      "tensor([ 1,  0,  3, 37, 77], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([ 1,  0,  3, 37, 77,  3], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1,  0,  3, 37, 77,  3,  1], device='cuda:0') -> tensor(71, device='cuda:0')\n",
      "tensor([ 1,  0,  3, 37, 77,  3,  1, 71], device='cuda:0') -> tensor(19, device='cuda:0')\n",
      "tensor([92], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([92,  1], device='cuda:0') -> tensor(71, device='cuda:0')\n",
      "tensor([92,  1, 71], device='cuda:0') -> tensor(70, device='cuda:0')\n",
      "tensor([92,  1, 71, 70], device='cuda:0') -> tensor(71, device='cuda:0')\n",
      "tensor([92,  1, 71, 70, 71], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([92,  1, 71, 70, 71,  1], device='cuda:0') -> tensor(34, device='cuda:0')\n",
      "tensor([92,  1, 71, 70, 71,  1, 34], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([92,  1, 71, 70, 71,  1, 34, 18], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([1], device='cuda:0') -> tensor(79, device='cuda:0')\n",
      "tensor([ 1, 79], device='cuda:0') -> tensor(82, device='cuda:0')\n",
      "tensor([ 1, 79, 82], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([ 1, 79, 82,  1], device='cuda:0') -> tensor(84, device='cuda:0')\n",
      "tensor([ 1, 79, 82,  1, 84], device='cuda:0') -> tensor(73, device='cuda:0')\n",
      "tensor([ 1, 79, 82,  1, 84, 73], device='cuda:0') -> tensor(77, device='cuda:0')\n",
      "tensor([ 1, 79, 82,  1, 84, 73, 77], device='cuda:0') -> tensor(69, device='cuda:0')\n",
      "tensor([ 1, 79, 82,  1, 84, 73, 77, 69], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([68], device='cuda:0') -> tensor(19, device='cuda:0')\n",
      "tensor([68, 19], device='cuda:0') -> tensor(1, device='cuda:0')\n",
      "tensor([68, 19,  1], device='cuda:0') -> tensor(26, device='cuda:0')\n",
      "tensor([68, 19,  1, 26], device='cuda:0') -> tensor(92, device='cuda:0')\n",
      "tensor([68, 19,  1, 26, 92], device='cuda:0') -> tensor(18, device='cuda:0')\n",
      "tensor([68, 19,  1, 26, 92, 18], device='cuda:0') -> tensor(3, device='cuda:0')\n",
      "tensor([68, 19,  1, 26, 92, 18,  3], device='cuda:0') -> tensor(36, device='cuda:0')\n",
      "tensor([68, 19,  1, 26, 92, 18,  3, 36], device='cuda:0') -> tensor(3, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "x, y = get_batch(\"train\")\n",
    "print(x.shape, y.shape)\n",
    "print('input')\n",
    "print(x)\n",
    "print('target')\n",
    "print(y)\n",
    "\n",
    "for b in range(bach_size):\n",
    "    for t in range(block_size):\n",
    "        context = x[b, :t+1]\n",
    "        target = y[b, t]\n",
    "        print(context, \"->\", target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BigramModel, self).__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        B, T, C = logits.size()\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "        else:\n",
    "                loss = None\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, n):\n",
    "        for _ in range(n):\n",
    "            logits = self.token_embedding_table(idx)\n",
    "            next_idx = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "            idx = torch.cat([idx, next_idx], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 95])\n",
      "tensor(4.9579, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(\"train\")\n",
    "m = BigramModel(vocab_size)\n",
    "m.to(device)\n",
    "logits, loss = m(x, y)  \n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nJ2)[ *)yLorct0s$/T@\\'>3zx1G~SbJD2)[Rt)1y&cV*_1\"6&sa.x}j7SDM<\\'^E?$67R)V\\\\N/u?ruzu5|<zEWYTv>V<H#A{j[($Z5'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(1, 1).long().to(device)\n",
    "g = m.generate(idx, 100)\n",
    "decode(g[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    def estimate_loss(model, eval_iters, block_size):\n",
    "        out = {}\n",
    "        model.eval()\n",
    "        for split in dataset:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for i in range(eval_iters):\n",
    "                x, y = get_batch(split, block_size)\n",
    "                _, loss = model(x, y)\n",
    "                losses[i] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "        model.train()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1000\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 4.983, validation loss: 4.966\n",
      "step: 100, train loss: 4.845, validation loss: 4.832\n",
      "step: 200, train loss: 4.715, validation loss: 4.712\n",
      "step: 300, train loss: 4.603, validation loss: 4.587\n",
      "step: 400, train loss: 4.472, validation loss: 4.473\n",
      "step: 500, train loss: 4.368, validation loss: 4.357\n",
      "step: 600, train loss: 4.252, validation loss: 4.237\n",
      "step: 700, train loss: 4.142, validation loss: 4.142\n",
      "step: 800, train loss: 4.051, validation loss: 4.046\n",
      "step: 900, train loss: 3.949, validation loss: 3.935\n"
     ]
    }
   ],
   "source": [
    "for step in range(n_iters):\n",
    "    x, y = get_batch(\"train\")\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = m(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % (n_iters//10) == 0:\n",
    "        losses = estimate_loss(m, 100, block_size)\n",
    "        print(f\"step: {step}, train loss: {losses['train']:.3f}, validation loss: {losses['validation']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iw1_b&qn,@6ilm(\"61i~IS#Tk1/2LqP{pocT#Nwry#tAG104fj[&RFa;idMVZ48^vS*I~fTQ\\'4 /A2t:NJ2ecfV]by$][BcXNJIzx[c/]i#@^]2o4!?,WY$,dK8B,D|SZ&U^m>Q+$,RS+\\'>NL2\\'Bg5f?@3_Rb\".]3fT:3+|le^+t= c}\\\\PkxW;&z94Bd\\';ikxJDh[238e?3wxh3$0x1\"A2{&eJlJWu;&YpV<$cuB,Z&8mMis0]}4?y(17k`d5$0C^X9~Z6i,W6y*ayG:1it=i.cK8BfgOU4,\\'dnY.$;iV$]L@z8TLJK8f.\\\\G3835}*r7PL@0igHG@t@B=k=B\"-2c2yD>,,\\'GEE3YQYQOr[2c>Nukx}dNVCQ3.(W7A2/TQm&uDF-[1a`Cdn7N(xdYpL(cet[Ue)^:_~1HJH$t!j_Ue5ts*2s:(c^0Fsk_xNh2:?ja!gb&eZyE2afgQy+A<ETMi(8-BGF+(GF>Ae2\\\\@#?87\"cr+teZ'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(1, 1).long().to(device)\n",
    "g = m.generate(idx, 500)\n",
    "\n",
    "decode(g[0].tolist()).replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic  transformer components\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, dropout=0.1):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = head_size\n",
    "        \n",
    "        self.keys = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        self.queries = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        self.value = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        \n",
    "        self.register_buffer('tril', torch.tril(torch.ones((x.shape[1], x.shape[1]))))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        k = self.keys(x) # B, block_size, head_size\n",
    "        q = self.queries(x) # B, block_size, head_size\n",
    "        v = self.value(x)\n",
    "\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) * self.head_size**-0.5  # (B, block_size, head_size) @ (B, head_size, block_size) -> (B, block_size, block_size)\n",
    "        wei = wei.masked_fill(self.tril == 0, float('-inf')) # B, block_size, block_size\n",
    "        wei = torch.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        out = wei @ v\n",
    "        return out\n",
    " \n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, embed_size, mlp_size, dropout=0.1):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.mlp_size = mlp_size\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, mlp_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_size, embed_size),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, n_heads, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = head_size\n",
    "        self.num_heads = n_heads\n",
    "            \n",
    "        self.attentions = nn.ModuleList([SelfAttention(embed_size, head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_heads * head_size, embed_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([attn(x) for attn in self.attentions], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block\n",
    "class Block(nn.Module): \n",
    "    def __init__(self, embed_size, mlp_size, n_heads, dropout=0.1):\n",
    "        super(Block, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = embed_size // n_heads\n",
    "        self.mlp_size = mlp_size\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "        self.mha = MultiHeadAttention(embed_size, self.head_size, n_heads, dropout)\n",
    "        self.mlp = Mlp(embed_size, mlp_size, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.mha(x) + self.ln1(x)\n",
    "        out = self.mlp(self.ln2(out)) + out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_blocks=8, block_size=8, n_heads=8, dropout=0.1):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, embedding_dim)\n",
    "        self.blocks = nn.Sequential(*\n",
    "                                    [Block(embedding_dim, embedding_dim*4, n_heads, dropout) for _ in range(n_blocks)],\n",
    "                                    nn.LayerNorm(embedding_dim)\n",
    "                                    )\n",
    "        self.lm_head = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        token_embeddings = self.token_embedding_table(idx) # B, T, C\n",
    "        positional_embeddings = self.positional_embedding_table(torch.arange(block_size).to(device) )# T, C\n",
    "        x = token_embeddings + positional_embeddings # \n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        B, T, C = logits.size()\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "        else:\n",
    "                loss = None\n",
    "                \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, n):\n",
    "        for _ in range(n):\n",
    "            logits, _ = self(idx[:, -self.block_size:])\n",
    "            next_idx = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "            idx = torch.cat([idx, next_idx], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384\n",
    "n_heads = 6\n",
    "head_size = 32//n_heads \n",
    "block_size = 256\n",
    "bach_size = 64\n",
    "n_iters = 10000\n",
    "lr = 3e-4\n",
    "n_blocks = 6    \n",
    "dropout = 0.2\n",
    "m = LanguageModel(vocab_size=vocab_size,\n",
    "                  embedding_dim=embedding_dim,\n",
    "                  block_size=block_size,\n",
    "                  n_heads=n_heads,\n",
    "                  dropout=dropout,)\n",
    "m.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 4.291, validation loss: 4.268\n",
      "step: 1000, train loss: 1.057, validation loss: 1.051\n",
      "step: 2000, train loss: 0.920, validation loss: 0.924\n",
      "step: 3000, train loss: 0.866, validation loss: 0.862\n",
      "step: 4000, train loss: 0.834, validation loss: 0.841\n",
      "step: 5000, train loss: 0.812, validation loss: 0.813\n",
      "step: 6000, train loss: 0.797, validation loss: 0.798\n",
      "step: 7000, train loss: 0.782, validation loss: 0.781\n",
      "step: 8000, train loss: 0.769, validation loss: 0.775\n",
      "step: 9000, train loss: 0.757, validation loss: 0.764\n",
      "step: 10000, train loss: 0.749, validation loss: 0.754\n"
     ]
    }
   ],
   "source": [
    "for step in range(n_iters+1):\n",
    "    x, y = get_batch(\"train\", block_size, bach_size)\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = m(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % (n_iters//10) == 0:\n",
    "        losses = estimate_loss(m, 100, block_size=block_size)\n",
    "        print(f\"step: {step}, train loss: {losses['train']:.3f}, validation loss: {losses['validation']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prompt, n):\n",
    "    idx = torch.tensor(encode(prompt)).unsqueeze(0).to(device)\n",
    "    idx = model.generate(idx, n)\n",
    "    return decode(idx[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (27) must match the size of tensor b (256) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mL:1/8\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mQ:1/8=180\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124mM:3/8\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mK:C\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(generate(m, prompt, \u001b[38;5;241m128\u001b[39m))\n",
      "Cell \u001b[1;32mIn[118], line 3\u001b[0m, in \u001b[0;36mgenerate\u001b[1;34m(model, prompt, n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(model, prompt, n):\n\u001b[0;32m      2\u001b[0m     idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encode(prompt))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 3\u001b[0m     idx \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(idx, n)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decode(idx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "Cell \u001b[1;32mIn[113], line 30\u001b[0m, in \u001b[0;36mLanguageModel.generate\u001b[1;34m(self, idx, n)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, n):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m---> 30\u001b[0m         logits, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(idx[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size:])\n\u001b[0;32m     31\u001b[0m         next_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmultinomial(F\u001b[38;5;241m.\u001b[39msoftmax(logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     32\u001b[0m         idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([idx, next_idx], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Assaf\\miniconda3\\envs\\transformers\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[113], line 16\u001b[0m, in \u001b[0;36mLanguageModel.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m     14\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding_table(idx) \u001b[38;5;66;03m# B, T, C\u001b[39;00m\n\u001b[0;32m     15\u001b[0m positional_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding_table(torch\u001b[38;5;241m.\u001b[39marange(block_size)\u001b[38;5;241m.\u001b[39mto(device) )\u001b[38;5;66;03m# T, C\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m token_embeddings \u001b[38;5;241m+\u001b[39m positional_embeddings \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks(x)\n\u001b[0;32m     18\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (27) must match the size of tensor b (256) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "L:1/8\n",
    "Q:1/8=180\n",
    "M:3/8\n",
    "K:C\n",
    "\"\"\"\n",
    "print(generate(m, prompt, 128))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
