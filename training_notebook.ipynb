{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import argparse\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['abc notation', 'control code'],\n",
       "        num_rows: 214122\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['abc notation', 'control code'],\n",
       "        num_rows: 2162\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dataset = datasets.load_from_disk(\"dataset\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer Encoding/Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding and decoding  \n",
    "vocab_size = 100\n",
    "\n",
    "def char_level_tokenizer(dataset):\n",
    "    chars = sorted(set(\"\\n\\n\".join(dataset[\"train\"][\"abc notation\"]+dataset[\"validation\"][\"abc notation\"])))\n",
    "    vocab_size = len(chars) \n",
    "    print(f\"vocab_size: {vocab_size}\")\n",
    "    print(f\"chars: {chars}\")\n",
    "    chat2index = {ch:i for i, ch in enumerate(chars)}\n",
    "    index2chat = {i:ch for i, ch in enumerate(chars)}\n",
    "    encode = lambda x: [chat2index[c] for c in x]\n",
    "    decode = lambda x: \"\".join([index2chat[c] for c in x])\n",
    "    return encode, decode, vocab_size\n",
    "\n",
    "def BPETokenizer(dataset):\n",
    "    from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "    # Initialize a tokenizer\n",
    "    tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "    # Define pre-tokenization rules (split on |, :, and whitespace)\n",
    "    # tokenizer.pre_tokenizer = pre_tokenizers.WhitespaceSplit()\n",
    "\n",
    "    # Train tokenizer on your dataset\n",
    "    trainer = trainers.BpeTrainer(special_tokens=[\"<START>\", \"<END>\", \"<PAD>\"], vocab_size=vocab_size)\n",
    "    tokenizer.train_from_iterator(dataset[\"train\"][\"abc notation\"], trainer=trainer, )\n",
    "\n",
    "    def encode(sequence):\n",
    "        \"\"\"\n",
    "        Encodes an ABC notation sequence into a list of token IDs.\n",
    "        \n",
    "        Args:\n",
    "        - tokenizer: The tokenizer object.\n",
    "        - sequence: A string of ABC notation to encode.\n",
    "\n",
    "        Returns:\n",
    "        - List of token IDs.\n",
    "        \"\"\"\n",
    "        # Add <START> and <END> tokens for sequence boundaries\n",
    "        sequence_with_tokens = f\"<START>{sequence}<END>\"\n",
    "        encoded = tokenizer.encode(sequence_with_tokens)\n",
    "        return encoded.ids\n",
    "    \n",
    "    def _decode(token_ids):\n",
    "        \"\"\"\n",
    "        Decodes a list of token IDs back into an ABC notation sequence.\n",
    "        \n",
    "        Args:\n",
    "        - tokenizer: The tokenizer object.\n",
    "        - token_ids: A list of token IDs to decode.\n",
    "\n",
    "        Returns:\n",
    "        - Decoded string of ABC notation.\n",
    "        \"\"\"\n",
    "        decoded = tokenizer.decode(token_ids)\n",
    "        # Remove <START> and <END> tokens if present\n",
    "        return decoded.replace(\"<START>\", \"\").replace(\"<END>\", \"\")\n",
    "\n",
    "    def decode(token_ids):\n",
    "        return \"\".join([_decode([t]) for t in token_ids])\n",
    "    return encode, decode, len(tokenizer.get_vocab()), tokenizer\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<START>': 0, '<END>': 1, '<PAD>': 2, '\\n': 3, ' ': 4, '!': 5, '\"': 6, '#': 7, '$': 8, '&': 9, \"'\": 10, '(': 11, ')': 12, '*': 13, '+': 14, ',': 15, '-': 16, '.': 17, '/': 18, '0': 19, '1': 20, '2': 21, '3': 22, '4': 23, '5': 24, '6': 25, '7': 26, '8': 27, '9': 28, ':': 29, ';': 30, '<': 31, '=': 32, '>': 33, '?': 34, '@': 35, 'A': 36, 'B': 37, 'C': 38, 'D': 39, 'E': 40, 'F': 41, 'G': 42, 'H': 43, 'I': 44, 'J': 45, 'K': 46, 'L': 47, 'M': 48, 'N': 49, 'O': 50, 'P': 51, 'Q': 52, 'R': 53, 'S': 54, 'T': 55, 'U': 56, 'V': 57, 'W': 58, 'X': 59, 'Y': 60, 'Z': 61, '[': 62, '\\\\': 63, ']': 64, '^': 65, '_': 66, '`': 67, 'a': 68, 'b': 69, 'c': 70, 'd': 71, 'e': 72, 'f': 73, 'g': 74, 'h': 75, 'i': 76, 'j': 77, 'k': 78, 'l': 79, 'm': 80, 'n': 81, 'o': 82, 'p': 83, 'q': 84, 'r': 85, 's': 86, 't': 87, 'u': 88, 'v': 89, 'w': 90, 'x': 91, 'y': 92, 'z': 93, '{': 94, '|': 95, '}': 96, '~': 97, ' |': 98, ' | ': 99}\n"
     ]
    }
   ],
   "source": [
    "encode, decode, vocab_size, tokenizer = BPETokenizer(dataset)\n",
    "vocab = tokenizer.get_vocab()\n",
    "vocab = dict(sorted(vocab.items(), key=lambda item: item[1]))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:1\n",
      "L:1/8\n",
      "M:6/8\n",
      "K:Bb\n",
      " F | B2 d c2 f | edc B2 F | GAB cec | BAG FGA | B2 d c2 f | edc B2 F | Gec AGA | B2 d B2 |: \n",
      " !fermata!F | D2 F D2 F | EGB cED | C2 E C2 E | DFA Bdf | geg fdb | gab [df]bb | dba gf=e |1 \n",
      " fff f2 :|2 fgf _edc!D.C.! ||\n",
      "X:1\n",
      "L:1/8\n",
      "M:6/8\n",
      "K:Bb\n",
      " F | B2 d c2 f | edc B2 F | GAB cec | BAG FGA | B2 d c2 f | edc B2 F | Gec AGA | B2 d B2 |: \n",
      " !fermata!F | D2 F D2 F | EGB cED | C2 E C2 E | DFA Bdf | geg fdb | gab [df]bb | dba gf=e |1 \n",
      " fff f2 :|2 fgf _edc!D.C.! ||\n"
     ]
    }
   ],
   "source": [
    "sample = \"\"\"X:1\\nL:1/8\\nM:6/8\\nK:Bb\\n F | B2 d c2 f | edc B2 F | GAB cec | BAG FGA | B2 d c2 f | edc B2 F | Gec AGA | B2 d B2 |: \\n !fermata!F | D2 F D2 F | EGB cED | C2 E C2 E | DFA Bdf | geg fdb | gab [df]bb | dba gf=e |1 \\n fff f2 :|2 fgf _edc!D.C.! ||\"\"\"\n",
    "# sample = \"\"\"1\\n A \\n1\"\"\"\n",
    "print(sample)\n",
    "print(decode(encode(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation data envoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data: torch.Size([57371649])\n",
      "validation_data: torch.Size([570241])\n"
     ]
    }
   ],
   "source": [
    "# encode training data\n",
    "# dataset = dataset.map(lambda x: {\"abc notation\": encode(x[\"abc notation\"])})\n",
    "\n",
    "training_data = torch.tensor(encode(dataset[\"train\"][\"abc notation\"]))\n",
    "print(f\"training_data: {training_data.shape}\")\n",
    "\n",
    "\n",
    "validation_data = torch.tensor(encode(dataset[\"validation\"][\"abc notation\"]))\n",
    "print(f\"validation_data: {validation_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bach generator\n",
    "def get_batch(split, block_size=8, bach_size=32):\n",
    "    if split == \"train\":\n",
    "        data = training_data\n",
    "    elif split == \"validation\":\n",
    "        data = validation_data\n",
    "    else:\n",
    "        raise ValueError(\"split must be 'train' or 'validation'\")\n",
    "    start_idx = torch.randint(0, data.size(0) - block_size, (bach_size,))\n",
    "    x = torch.stack([data[idx:idx+block_size] for idx in start_idx]).to(device)\n",
    "    y = torch.stack([data[idx+1:idx+block_size+1] for idx in start_idx]).to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 29, 27, 22, 24, 21, 63, 81, 47, 29, 20, 18, 27, 63, 81, 52, 29, 22, 18, 27, 32, 20, 19, 19, 63, 81, 48, 29, 25, 18, 27, 63, 81, 46, 29, 42, 63, 81, 4, 37, 71, 71, 4, 74, 71, 71, 99, 72] -> 37\n",
      "X:8352\\nL:1/8\\nQ:3/8=100\\nM:6/8\\nK:G\\n Bdd gdd | e -> B\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "bach_size = 1\n",
    "block_size = 48\n",
    "x, y = get_batch(\"train\", block_size=block_size, bach_size=bach_size)\n",
    "for b in range(bach_size):\n",
    "    for t in range(block_size):\n",
    "        context = x[b, :t+1]\n",
    "        target = y[b, t]\n",
    "    print(context.tolist(), \"->\", target.item())\n",
    "    print(decode(context.tolist()), \"->\", decode([target.item()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    def estimate_loss(model, eval_iters, block_size):\n",
    "        out = {}\n",
    "        model.eval()\n",
    "        for split in dataset:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for i in range(eval_iters):\n",
    "                x, y = get_batch(split, block_size)\n",
    "                _, loss = model(x, y)\n",
    "                losses[i] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "        model.train()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super(BigramModel, self).__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        B, T, C = logits.size()\n",
    "        \n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "        else:\n",
    "                loss = None\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, n):\n",
    "        for _ in range(n):\n",
    "            logits = self.token_embedding_table(idx)\n",
    "            next_idx = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "            idx = torch.cat([idx, next_idx], dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 1000])\n",
      "tensor(7.3779, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x, y = get_batch(\"train\")\n",
    "m = BigramModel(vocab_size)\n",
    "m.to(device)\n",
    "logits, loss = m(x, y)  \n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dedc ]\" ged FAA gdc >^ Amin BGAG cBAB \\\\\\'/ q e 88 Bc AFA edBd A4 3EFG ded dor Bdg ]/[ {/ ga dBA GAG dBBA f2e2 a D7 3def /). DGBG Adf 116 s cee BB e2e2 \\', afa |:\" FDE 44 ||\", fe Tf2 AGFE Z 69 - Bd FAc 77 egdg efed 12 afdf ga cAc egdB faa geg #\" 24 a3 ly gec cdc BdBG BAA AGEG cAGE eB af GFD gagf B2B2 ce 3DEF |]: BdBG nL EFA d2 c2B2 c2e2 or 77 GEC fded low F6 ac 55 Bdf ]/ >\" 2 dfd'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(1, 1).long().to(device)\n",
    "g = m.generate(idx, 100)\n",
    "decode(g[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    def estimate_loss(model, eval_iters, block_size):\n",
    "        out = {}\n",
    "        model.eval()\n",
    "        for split in dataset:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for i in range(eval_iters):\n",
    "                x, y = get_batch(split, block_size)\n",
    "                _, loss = model(x, y)\n",
    "                losses[i] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "        model.train()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1000\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 7.402, validation loss: 7.404\n",
      "step: 100, train loss: 7.324, validation loss: 7.322\n",
      "step: 200, train loss: 7.229, validation loss: 7.233\n",
      "step: 300, train loss: 7.146, validation loss: 7.148\n",
      "step: 400, train loss: 7.054, validation loss: 7.054\n",
      "step: 500, train loss: 6.969, validation loss: 6.969\n",
      "step: 600, train loss: 6.890, validation loss: 6.888\n",
      "step: 700, train loss: 6.811, validation loss: 6.803\n",
      "step: 800, train loss: 6.728, validation loss: 6.720\n",
      "step: 900, train loss: 6.650, validation loss: 6.642\n"
     ]
    }
   ],
   "source": [
    "for step in range(n_iters):\n",
    "    x, y = get_batch(\"train\")\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = m(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % (n_iters//10) == 0:\n",
    "        losses = estimate_loss(m, 100, block_size)\n",
    "        print(f\"step: {step}, train loss: {losses['train']:.3f}, validation loss: {losses['validation']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'39 dc fddf ve EAA dcd efgf 3ABA Bee Bdf fdcA cBcA \\'/ 69 dGBG e3 cAc cBc efg } im B3 ]) DEFG BF 42 efg A4 !> egdg adfd ,, GGG 54 dBG 88 cAB ff 48 gg fdec Bdef Cm GG c2 36 bag |\"^( Gc agef 70 |] efga z4 Bf 3efg GFE BGdG f3 eaag ABG 16 FGAc ceg BcBA dAF _B \"\" BGBd ag Ec 17 BABc 3 ea |\" C7 gedc B2d2 _e 3A gfg BGB FD FAdA cdB dcAG & EAA edef 34 BGA it al Db gef gab 26 F2A2 D6 aec eG Adde GFEF ecdB ve ||\\', FGAF dBAB g6 FAdf n 35 ABde dBAG ,< ]\" dg FAF 3ded edB gd fdcA ||\"^ GFEF 11 cAFA >^ G2G2 SO lide 59 3BcB age GFE Gc # BGE ecBc aba 38 egdB im Ae BAF Edor 180 BF Af CF aA \"{ ba ca 35 fdf age d3 - dF GEC .\" S cBcA AGEF GFED BdBG 47 Ab GABc 21 s fgag d4 fa 23 im dGBG gabg efg cBc ar dcA Te GF 9 A z3 3BAG DC BAA fece cBAc I BG H fA Amin GABc dfec AFF cdB eG 3ABA on GBA 27 dE B4 g3 gfe BAF cGE wedge z f2f2 AD dcAF 3AAA eA I V g6 : & 92 GBB U ga Add 54 BdAF AcBA cAG eAcA c4 f2f2 b2 dAFA CA Gg .\" baf aba s 46 FE EB Ab #\" cdeg _ 56 wedge j /). 66 im AGFG DAFA DGG c2B2 ||\" AGE 40 d2B2 EGB efg ded gee g2f2 BGBd 3cBA GBB be s ecA Db |]: _B2 J B4 TB2 95 SO fafd FDFA dA AGFD abaf c cedc Bmin dA # Ddor ||[ 50 BFAF adfd |\"^ DEGA dBAB dGG c3 GD S egdg dfd cA nL Emin Bb7 [ Bb7 DA 7 dfaf D7 e2e2 wedge dfe Gmin cF ecBA AGF ABcd FAdA Ee ABc GAB 62 >\" cAce A age Adf a3 d2c2 adfd Dm Bf A8 cABc DGG BEE gdBG GAB aece BAGB agf cF DEG ggg gA dBAB fefg Ador cedc 69 EC >. _c !> dGG ff fa 3FGA 3ded :|\\', fgf egfa B Addc edc - z4 Bm ABAG @ der fermata DC f4 GABd 86 17 ceg gf AA Z BAGB B7 79 Eb c2 3fga BB be *\" cee geg cded ::\"^ #\" \\' 36 ED \"{ dBGA Gmin A8 a2 = A7 ^ g2 B2A2 G aga 53 e2c2 Ddor dg 82 gfg T >. 4 3fed r d6 |]\\', Dd Dm G3 B2B2 F2 DA Emin |]\", 11 dAF st fafd Bdc FEF GFED FGAF Bg C4 GFE gbag A3 $ ,) 98 ]> AcA ix F6 fddf 115 ecBA {/ 3efe 44 dBAc cA 35 cee EG < cA Bc GG low F defg ([ \\' z4 oder CD Bc afdf dedc [ BGE \" defg A4 g6 Aa b AGEF ced s 3FED EFGA'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.zeros(1, 1).long().to(device)\n",
    "g = m.generate(idx, 500)\n",
    "\n",
    "decode(g[0].tolist()).replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic  transformer components\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, dropout=0.1, block_size=8):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = head_size\n",
    "        \n",
    "        self.keys = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        self.queries = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        self.value = nn.Linear(self.embed_size, self.head_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.keys(x) # B, block_size, head_size\n",
    "        q = self.queries(x) # B, block_size, head_size\n",
    "        v = self.value(x)\n",
    "\n",
    "        tril = torch.tril(torch.ones(T, T)).to(x.device)    \n",
    "        wei = q @ k.transpose(-2, -1) * self.head_size**-0.5  # (B, block_size, head_size) @ (B, head_size, block_size) -> (B, block_size, block_size)\n",
    "        wei = wei.masked_fill(tril == 0, float('-inf')) # B, block_size, block_size\n",
    "        wei = torch.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        out = wei @ v\n",
    "        return out\n",
    " \n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, embed_size, mlp_size, dropout=0.1):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.mlp_size = mlp_size\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, mlp_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_size, embed_size),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, n_heads, dropout=0.1, block_size=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = head_size\n",
    "        self.num_heads = n_heads\n",
    "        self.attentions = nn.ModuleList([SelfAttention(embed_size, head_size, block_size=block_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_heads * head_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([attn(x) for attn in self.attentions], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block\n",
    "class Block(nn.Module): \n",
    "    def __init__(self, embed_size, mlp_size, n_heads, dropout=0.1, block_size=8):\n",
    "        super(Block, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.head_size = embed_size // n_heads\n",
    "        self.mlp_size = mlp_size\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "        self.mha = MultiHeadAttention(embed_size, self.head_size, n_heads, dropout, block_size)\n",
    "        self.mlp = Mlp(embed_size, mlp_size, dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.mha(x) + self.ln1(x)\n",
    "        out = self.mlp(self.ln2(out)) + out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_blocks=8, block_size=8, n_heads=8, dropout=0.1):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.positional_embedding_table = nn.Embedding(block_size, embedding_dim)\n",
    "        self.blocks = nn.Sequential(*\n",
    "                                    [Block(embedding_dim,\n",
    "                                           embedding_dim*4,\n",
    "                                           n_heads, dropout,\n",
    "                                           block_size) for _ in range(n_blocks)],\n",
    "                                    nn.LayerNorm(embedding_dim)\n",
    "                                    )\n",
    "        self.lm_head = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.shape\n",
    "        token_embeddings = self.token_embedding_table(x) # B, T, C\n",
    "        positional_embeddings = self.positional_embedding_table(torch.arange(T).to(device) )# T, C\n",
    "        x = token_embeddings + positional_embeddings # \n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        B, T, C = logits.size()\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(logits.view(B*T, C), targets.view(B*T))\n",
    "        else:\n",
    "                loss = None\n",
    "                \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, n):\n",
    "        for _ in range(n):\n",
    "            logits, _ = self(idx[:, -self.block_size:])\n",
    "            next_idx = torch.multinomial(F.softmax(logits[:, -1], dim=1), 1)\n",
    "            idx = torch.cat([idx, next_idx], dim=1)\n",
    "        return idx\n",
    "\n",
    "    def save_model(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "        \n",
    "    def load_model(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 384 \n",
    "n_heads = 6\n",
    "head_size = 32//n_heads \n",
    "block_size = 256 # context window size\n",
    "bach_size = 64\n",
    "n_iters = 1000\n",
    "lr = 3e-4\n",
    "n_blocks = 6    \n",
    "dropout = 0.2\n",
    "m = LanguageModel(vocab_size=vocab_size,\n",
    "                  embedding_dim=embedding_dim,\n",
    "                  block_size=block_size,\n",
    "                  n_heads=n_heads,\n",
    "                  dropout=dropout,)\n",
    "m.to(device)\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  10%|█         | 101/1001 [01:09<1:45:14,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100, train loss: 2.179, validation loss: 2.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  20%|██        | 201/1001 [02:19<1:36:04,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 200, train loss: 1.840, validation loss: 1.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  30%|███       | 301/1001 [03:31<1:24:00,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 300, train loss: 1.625, validation loss: 1.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  40%|████      | 401/1001 [04:43<1:12:42,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 400, train loss: 1.509, validation loss: 1.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  50%|█████     | 501/1001 [05:56<1:00:36,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 500, train loss: 1.401, validation loss: 1.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  60%|██████    | 601/1001 [07:10<48:26,  7.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 600, train loss: 1.314, validation loss: 1.314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  70%|███████   | 701/1001 [08:21<37:01,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 700, train loss: 1.253, validation loss: 1.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Iterations:  80%|███████▉  | 800/1001 [09:10<01:44,  1.92it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for step in tqdm(range(n_iters+1),  total=n_iters+1, desc=\"Training Iterations\"): \n",
    "    x, y = get_batch(\"train\", block_size, bach_size)\n",
    "    optimizer.zero_grad()\n",
    "    logits, loss = m(x, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % (n_iters//5) == 0 and step :\n",
    "        losses = estimate_loss(m, 25, block_size=block_size)\n",
    "        print(f\"step: {step}, train loss: {losses['train']:.3f}, validation loss: {losses['validation']:.3f}\")\n",
    "\n",
    "m.save_model(r\"models/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, prompt, n):\n",
    "    encoded_prompt = torch.tensor(encode(prompt)).unsqueeze(0).to(device)\n",
    "    print(encoded_prompt)\n",
    "    out = model.generate(encoded_prompt, n)\n",
    "    return decode(out[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,  46,  27,  21,  16,  21,  36,  27,  53,  83, 341,  15,  44,  27,\n",
      "          40, 135, 324, 594,  93, 594, 594,  93, 103, 125, 102, 113,  93, 722,\n",
      "          98,  99,  93,   1]], device='cuda:0')\n",
      "M : 4 / 4 C : T r ad . K : G |: GABc dedB | dedB dedB | c2 ec B2 dB | c2A2 A2 BA | abc ADD ` C2 |\"^( GABd GBAF ccc 14 94 EF edcB G3 j fdB 115 72 |[ N 34 \"^/\" fd EF edBd B2G2 fg 6 aga gfe F F d2d2 cBAB Q BdAF cdeg ABcA a ). G2G2 94 48 cdef GEE Bd ceg dfa AGFD GFEF k ddd cAeA C3 gef \"{ Amin Ee afec ||[ c2A2 egdB BGGB dBAG c2\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "M:4/4\n",
    "C:Trad.\n",
    "K:G\n",
    "|:GABc dedB|dedB dedB|c2ec B2dB|c2A2 A2BA|\n",
    "\"\"\"\n",
    "m = LanguageModel(vocab_size=vocab_size,\n",
    "                  embedding_dim=embedding_dim,\n",
    "                  block_size=block_size,\n",
    "                  n_heads=n_heads,\n",
    "                  dropout=dropout)\n",
    "# m.load_model(r\"models/model.pth\")\n",
    "m.to(device)\n",
    "print(generate(m, prompt, 64))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
